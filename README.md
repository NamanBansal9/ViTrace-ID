# PersonaTrace: Fine-Tuned Vision Transformer for Target Person Identification

## ğŸš€ Overview

**PersonaTrace** is an end-to-end computer vision system designed to **identify and track a specific person across an entire video** using minimal reference images. The project combines **YOLOv8-based person detection** with a **fine-tuned Vision Transformer (ViT)** to generate robust identity embeddings and perform accurate matching with temporal consistency.

This project is built with a strong focus on **real-world deployment**, **model persistence**, and **evaluation reproducibility**, ensuring that results remain stable across sessions without requiring repeated training or inference.

---

## ğŸ¯ Key Features

* ğŸ” **High-accuracy person detection** using YOLOv8
* ğŸ§  **Vision Transformer (ViT) fine-tuned for identity discrimination**
* ğŸ§¬ **Embedding-based person re-identification**
* â±ï¸ **Temporal smoothing** for stable video-level predictions
* ğŸ’¾ **Model & embeddings persistence** (no reruns required)
* ğŸ“Š **Precision, Recall & F1-score evaluation**
* âš™ï¸ Modular, deployment-ready pipeline

---

## ğŸ§© System Architecture

```
Video Input
   â†“
Frame Extraction
   â†“
YOLOv8 Person Detection
   â†“
Identity-Relevant Crop Filtering
   â†“
ViT Embedding Extraction
   â†“
Similarity Matching
   â†“
Temporal Smoothing
   â†“
Final Target Person Frames
```

---

## ğŸ“ Project Structure

```
project-root/
â”‚                   
â”œâ”€â”€ embeddings.npy             # ViT embeddings (persistent)
â”œâ”€â”€ matched_indices.npy        # Final matched frame indices
â”œâ”€â”€ vit_finetuned.pth          # Fine-tuned ViT model (Git LFS)
â”œâ”€â”€ yolov8n.pt / yolov8x.pt    # YOLOv8 detection models
â”œâ”€â”€ main.ipynb                 # Complete pipeline notebook
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ§  Model Details

### Person Detection

* **Model**: YOLOv8
* **Classes Used**: Person
* **Purpose**: Accurate bounding box extraction for human subjects

### Identity Modeling

* **Backbone**: Vision Transformer (ViT-B/16)
* **Pretraining**: ImageNet
* **Fine-Tuning**: Binary identity classification
* **Output**: Identity-aware embeddings

---

## ğŸ“Š Evaluation Metrics

The system is evaluated using ground-truth identity annotations:

* **Precision**: Measures false positives
* **Recall**: Measures missed detections
* **F1-Score**: Balanced performance metric

> Final fine-tuned model achieved **near-perfect F1-score**, demonstrating strong generalization across frames.

---

## âš¡ Quick Start

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/your-username/PersonaTrace.git
cd PersonaTrace
```

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Run Pipeline

Open `main.ipynb` and execute cells sequentially.

> All models and embeddings are pre-saved â€” **no retraining required**.

---

## ğŸ› ï¸ Deployment Notes

* Supports **CPU and GPU** environments
* Compatible with **Windows / Linux / macOS**
* Designed for **offline reproducibility**
* Large model files handled via **Git LFS**

---

## ğŸŒŸ Use Cases

* Video surveillance & forensics
* Sports analytics
* Content-based video retrieval
* Human behavior analysis
* Smart video indexing

---

## ğŸ“Œ Future Enhancements

* Multi-person identity tracking
* Real-time inference pipeline
* Web-based UI dashboard
* Cross-video identity linking

---

## ğŸ¤ Acknowledgements

* Ultralytics YOLOv8
* PyTorch & timm
* Open-source CV community

---

## ğŸ“œ License

This project is released under the **MIT License**.

---

## ğŸ‘¤ Author
**NAMAN BANSAL**
Developed with â¤ï¸ as an advanced computer vision system for identity-aware video understanding.

If you find this project useful, please â­ the repository!

